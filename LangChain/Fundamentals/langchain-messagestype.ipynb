{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a00987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#AZURE OPEN AI MODEL INTEGRATION\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "#OpenAI API Key unavailable, but Azure OpenAI keys available. Hence, using Azure OpenAI model.\n",
    "model = init_chat_model(\n",
    "    os.getenv(\"AZURE_OPENAI_LLM_MODEL\"),\n",
    "    model_provider=\"azure_openai\",\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_LLM_MODEL\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2023-05-15\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802c6980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The theory of relativity states that space and time are interwoven, and the laws of physics are the same for all observers regardless of their relative motion.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 16, 'total_tokens': 48, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-chat-2025-10-03', 'system_fingerprint': 'fp_88bf7c189b', 'id': 'chatcmpl-CxVfizE6FVR0DIQFzKJdTYFfYodtX', 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='lc_run--019bb6d7-76c5-72e1-adf6-497c28492a92-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 16, 'output_tokens': 32, 'total_tokens': 48, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Explain the theory of relativity in one line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3419d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Artificial intelligence is transforming healthcare by enhancing diagnostics, treatment planning, and patient care. It enables early disease detection through image analysis, streamlines administrative tasks, and supports personalized medicine. AI-driven tools improve efficiency, reduce human errors, and help healthcare professionals make data-driven decisions, ultimately leading to better patient outcomes and healthier communities.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 22, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-chat-2025-10-03', 'system_fingerprint': 'fp_88bf7c189b', 'id': 'chatcmpl-CxVfiEeM4nS3fSH3YLB6BaEvHRenq', 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='lc_run--019bb6d7-7f40-7db2-9164-16b5bfe24391-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 22, 'output_tokens': 65, 'total_tokens': 87, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Prompts - ideal straightforward prompt where you don't need to provide much context or retain conversation history.\n",
    "model.invoke(\"Write me a 50 word paragraph on the importance of AI in healthcare.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "470ee7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nMessage Prompts - ideal for chatbots or conversational agents where maintaining context and history is crucial.\\n\\nSystem Message - Tell model how to behave and provide context for interactions.\\nHuman Message - User input or queries.\\nAI Message - Model's responses including text, tool calls and metadata.\\nTool Message - Output from tool calls used by the model.\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Message Prompts - ideal for chatbots or conversational agents where maintaining context and history is crucial.\n",
    "\n",
    "System Message - Tell model how to behave and provide context for interactions.\n",
    "Human Message - User input or queries.\n",
    "AI Message - Model's responses including text, tool calls and metadata.\n",
    "Tool Message - Output from tool calls used by the model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93e4e419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let’s imagine the theory of relativity wrapped in verse—turning equations into imagery while keeping the meaning intact:\n",
      "\n",
      "---\n",
      "\n",
      "**“Relativity”**\n",
      "\n",
      "Time is a river, never the same,  \n",
      "Bending near mountains of mass and name.  \n",
      "Light is the traveler, steady and true,  \n",
      "Yet space can ripple beneath its view.  \n",
      "\n",
      "You, on your train with clock in hand,  \n",
      "See seconds drip like golden sand.  \n",
      "I, on the platform watching you fly,  \n",
      "See your time stretch long as the sky.  \n",
      "\n",
      "There is no place where truth stands still—  \n",
      "The cosmos curves to a hidden will.  \n",
      "Mass whispers softly, “Come, fold near,”  \n",
      "And space-time listens, bends to hear.  \n",
      "\n",
      "So all that we measure, and all we declare,  \n",
      "Depends on the motion that carries us there.  \n",
      "Nothing is fixed, yet harmony reigns—  \n",
      "The universe dances through flexible chains.  \n",
      "\n",
      "And in that dance, one truth we find:  \n",
      "To know the cosmos, free your mind—  \n",
      "For space and time are lovers entwined,  \n",
      "Their steps forever redefined.  \n",
      "\n",
      "---\n",
      "\n",
      "Would you like me to add a brief explanation of how each stanza maps to Einstein’s ideas?\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You an expert of poetry and metaphors.\"),\n",
    "    HumanMessage(content=\"Explain the theory of relativity using a poem.\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c41112b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can read a CSV file easily in Python using **pandas** with the `read_csv()` function.  \n",
      "\n",
      "Here’s a quick example:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Read a CSV file\n",
      "df = pd.read_csv(\"data.csv\")\n",
      "\n",
      "# Display the first 5 rows\n",
      "print(df.head())\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "- **`import pandas as pd`**: Imports the pandas library with a short alias (`pd`).\n",
      "- **`pd.read_csv(\"data.csv\")`**: Reads the CSV file into a **DataFrame** (a pandas table-like structure).\n",
      "- **`df.head()`**: Shows the first 5 rows for a quick peek.\n",
      "\n",
      "---\n",
      "\n",
      "### Common Useful Parameters:\n",
      "```python\n",
      "df = pd.read_csv(\n",
      "    \"data.csv\",\n",
      "    delimiter=\",\",      # Change delimiter if needed (e.g. \";\" or \"\\t\")\n",
      "    header=0,           # Row number to use as column names\n",
      "    index_col=None,     # Column to use as index\n",
      "    na_values=[\"NA\"],   # Define missing value markers\n",
      "    usecols=[\"Name\", \"Age\"],  # Load specific columns\n",
      "    encoding=\"utf-8\"    # Specify file encoding if needed\n",
      ")\n",
      "```\n",
      "\n",
      "If your file is large, you can also read it in chunks:\n",
      "\n",
      "```python\n",
      "for chunk in pd.read_csv(\"large_file.csv\", chunksize=5000):\n",
      "    print(chunk.shape)\n",
      "```\n",
      "\n",
      "This approach lets you process large datasets efficiently.\n"
     ]
    }
   ],
   "source": [
    "#Detailed info to LLM through System Message\n",
    "\n",
    "system_message = SystemMessage(\"\"\"\n",
    "You are a Python programming expert with specialization in Machine Learning and AI.\n",
    "Always provide code snippets and explain your reasoning.\n",
    "Be concise but thorough in your explanations.\n",
    "\"\"\")\n",
    "\n",
    "messages = [\n",
    "    system_message,\n",
    "    HumanMessage(content=\"How to read CSV in python using pandas?\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d62e4061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMessages are objects that contain - \\n1. Role - system, human, ai, tool\\n2. Content - actual content of the message\\n3. Metadata - additional information about the message/response information\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Messages are objects that contain - \n",
    "1. Role - system, human, ai, tool\n",
    "2. Content - actual content of the message\n",
    "3. Metadata - additional information about the message/response information\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc212b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! Here’s a simple way to think about **quantum computing**:\\n\\nA normal computer — like the one you’re using now — works with **bits**, which are tiny switches that can be either **0 or 1**. Everything your computer does, from running apps to showing videos, comes from manipulating huge numbers of those 0s and 1s in different ways.\\n\\nA **quantum computer**, on the other hand, uses **quantum bits**, or **qubits**. Qubits are special because, thanks to the strange rules of quantum physics, each qubit can be **0, 1, or both at the same time** (this is called **superposition**).  \\n\\nAlso, qubits can be **entangled**, meaning the state of one qubit is linked to the state of another — even if they’re far apart. This allows quantum computers to perform certain calculations in parallel, exploring many possibilities at once.\\n\\nThat doesn’t mean they can replace normal computers for everything, but for some kinds of problems — like simulating molecules, optimizing complex systems, or breaking certain encryption schemes — quantum computers could be **much faster** than traditional ones.\\n\\n**In short:**  \\n- Ordinary computers use bits (0 or 1).  \\n- Quantum computers use qubits (0 *and* 1 at the same time).  \\n- This lets them handle certain complex problems far more efficiently.\\n\\nWould you like an everyday analogy (like coins or spinning tops) to make it even easier to picture?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 310, 'prompt_tokens': 16, 'total_tokens': 326, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-chat-2025-10-03', 'system_fingerprint': 'fp_88bf7c189b', 'id': 'chatcmpl-CxVfucdr2mM2UPksyZEBqReE2sLCd', 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='lc_run--019bb6d7-ad33-7671-999f-875642ff1fd8-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 16, 'output_tokens': 310, 'total_tokens': 326, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Message Metadata Example\n",
    "human_msg = HumanMessage(\n",
    "    content=\"Explain quantum computing in simple terms.\",\n",
    "    name=\"Alice\",\n",
    "    id=\"msg-001\"\n",
    ")\n",
    "response = model.invoke([human_msg])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d2aaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='The **Pythagorean theorem** is a fundamental principle in geometry that applies to **right-angled triangles** (triangles that have one 90° angle).  \\n\\nIt states that:  \\n\\n\\\\[\\na^2 + b^2 = c^2\\n\\\\]\\n\\nWhere:  \\n- \\\\(a\\\\) and \\\\(b\\\\) are the lengths of the two legs (the sides that form the right angle), and  \\n- \\\\(c\\\\) is the length of the **hypotenuse** (the side opposite the right angle, and the longest side of the triangle).\\n\\nIn words, the theorem says:  \\n> The square of the hypotenuse is equal to the sum of the squares of the other two sides.\\n\\n**Example:**  \\nIf one leg of a right triangle is 3 units and the other is 4 units, the hypotenuse can be found as:\\n\\\\[\\nc = \\\\sqrt{3^2 + 4^2} = \\\\sqrt{9 + 16} = \\\\sqrt{25} = 5\\n\\\\]\\n\\nWould you like me to show how this can be used to solve a real-world problem?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 236, 'prompt_tokens': 67, 'total_tokens': 303, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-chat-2025-10-03', 'system_fingerprint': 'fp_88bf7c189b', 'id': 'chatcmpl-CxVfza9He3BF3bJJtXPwh4vmWxq0f', 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}} id='lc_run--019bb6d7-c086-7370-9d3d-2fb6961b67f4-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 67, 'output_tokens': 236, 'total_tokens': 303, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "#AI Message\n",
    "\n",
    "from langchain.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "ai_msg = AIMessage(\"I'd be happy to help with that!\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant.\"),\n",
    "    HumanMessage(\"Can you assist me with my homework?\"),\n",
    "    ai_msg,\n",
    "    AIMessage(\"Sure, what subject is your homework in?\"),\n",
    "    HumanMessage(\"It's in mathematics. What is the Pythagorean theorem?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(type(response))\n",
    "print(response)  # Model's response to the last human message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ddbd785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tool Message\n",
    "from langchain.messages import ToolMessage, AIMessage\n",
    "\n",
    "ai_msg = AIMessage(\n",
    "    content=[],\n",
    "    tool_calls=[\n",
    "        {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"args\": {\"location\": \"San Francisco\"},\n",
    "            \"id\": \"call_123\"\n",
    "        }\n",
    "    ],\n",
    "\n",
    ")\n",
    "\n",
    "weather_result = \"Sunny, 68°F\"\n",
    "\n",
    "tool_msg = ToolMessage(\n",
    "    content=weather_result,\n",
    "    tool_call_id=\"call_123\" #Must match call id\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a weather assistant.\"),\n",
    "    HumanMessage(\"What's the weather like in San Francisco?\"),\n",
    "    ai_msg,\n",
    "    tool_msg\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1ecd06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='It’s currently sunny in San Francisco with a temperature of 68°F.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 53, 'total_tokens': 69, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-chat-2025-10-03', 'system_fingerprint': 'fp_88bf7c189b', 'id': 'chatcmpl-CxVg37w1oEQRVeIoLESsyfmCNelg3', 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}} id='lc_run--019bb6d7-cfff-7731-ab45-5993b80cb87b-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 53, 'output_tokens': 16, 'total_tokens': 69, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(messages)\n",
    "print(response)  # Model's response after receiving tool output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_genai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
